{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KQAYuDB7qBO"
   },
   "source": [
    "## Download data from Google Drive to colab environment\n",
    "First we need to mount the Google Drive folder into colab. <br>\n",
    "Then we copy the data for this exercise to the colab VM and untar it \"locally\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFFZmQS38Q3A"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Btv_BSWk7l6n"
   },
   "outputs": [],
   "source": [
    " \n",
    "!echo \"Copying Data Locally (Male/Female Radiograph)\"\n",
    "!tar xf \"/content/drive/My Drive/ML4MI_BOOTCAMP_DATA/MaleFemaleRadiograph.tar\" --directory /home/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0TZKhgBSiA8"
   },
   "source": [
    "## Setup packages and data\n",
    "First import the packages you'll need. From Keras, we'll need an data generator package, layers package, a package containing optimizres, and a package that builds/configures models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9iS7xV-SiBC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTOhwmFnSiBI"
   },
   "source": [
    "Define data location and image dimensions. Data is split into train (50%), validate (25%), and test (25%).\n",
    "We'll use Kera's ImageDataGenerator method to read in the data. Data (.png files) is sorted into folders with the following structure <br>\n",
    ">train/<br>\n",
    "&ensp;Class1/<br>\n",
    "&ensp;&ensp;xx1.png<br>\n",
    "&ensp;&ensp;xx2.png<br>\n",
    "&ensp;&ensp;...<br>\n",
    "&ensp;Class2/<br>\n",
    "&ensp;&ensp;yy1.png<br>\n",
    "&ensp;&ensp;yy2.png<br>\n",
    "test/<br>\n",
    "&ensp;Class1/  ...<br>\n",
    "&ensp;Class2/  ...<br>\n",
    "validation/<br>\n",
    "&ensp;Class1/ ...<br>\n",
    "&ensp;Class2/ ...<br>\n",
    "\n",
    "We tell Keras where the directories are. It counts the number of subfolders and makes each one a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B68WRHghSiBJ"
   },
   "outputs": [],
   "source": [
    "data_home_dir = '/home/MaleFemaleRadiograph/data/'\n",
    "train_dir = data_home_dir + 'train'\n",
    "validation_dir = data_home_dir + 'validation'\n",
    "dims = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm5QJIzvSiBM"
   },
   "source": [
    "When we define the ImageDataGenerator object, we tell it to normalize the .png images by the max (255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJIruauGSiBN"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWTH4twUSiBQ"
   },
   "source": [
    "Keras will read the files continuously from disk. We tell it where to read, how many to read at a time, what dimensions to resample the images to, and how many image channels there are. These generators will then generate batches of images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTJ5jV3TSiBR"
   },
   "outputs": [],
   "source": [
    "train_generator =      train_datagen.flow_from_directory(train_dir, batch_size=20, target_size=(dims,dims), class_mode='binary', color_mode='grayscale')\n",
    "validation_generator = valid_datagen.flow_from_directory(validation_dir,batch_size=20, target_size=(dims,dims), class_mode='binary',color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YPRRjfOSiBV"
   },
   "source": [
    "\n",
    "## Build network \n",
    "First part of the graph is the input, which, at this point, we only need to tell it its shape (we'll define where the inputs come from when we build the model later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EexLFjjuSiBW"
   },
   "outputs": [],
   "source": [
    "img_input = layers.Input(shape=(dims,dims,1), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "787x2GgcSiBZ"
   },
   "source": [
    "Now we build our layers of the network. The format is layer_name(_config_info_)(_input_to_layer_).\n",
    "Try a simple layer with 1 convolution, max pooling, and a fully-connected layer (these are _not_ the best parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJ0a7in6SiBa"
   },
   "outputs": [],
   "source": [
    "x = layers.Conv2D(15, (3, 3), strides=(4,4), padding='same')(img_input)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=None)(x)\n",
    "x = layers.Flatten()(x)     #reshape to 1xN \n",
    "x = layers.Dense(20, activation='relu')(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)    #sigmoid for binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZdGrNzMSiBe"
   },
   "source": [
    "## Configure and train model\n",
    "We define our model, define the input(s) and output(s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKDgCmOLSiBf"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=img_input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnyZIKs_SiBi"
   },
   "source": [
    "We then compile it and determine our loss function, our optimizer, and the metrics we want to calculate. This builds the \"graph\" of our model and computes the functions needed to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxl0-TbQSiBj"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimizers.RMSprop(learning_rate=1e-5), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECxchiaNSiBk"
   },
   "source": [
    "This next steps kicks off the network training. This is where we actually feed the compiled model the data (in batches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfIba-7DSiBl"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, steps_per_epoch=130, epochs=15, \n",
    "                              validation_data=validation_generator, validation_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Blf0r681SiBp"
   },
   "source": [
    "## Evaluate performance\n",
    "First, let's calculate the performance on our testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORnirixPSiBq"
   },
   "outputs": [],
   "source": [
    "test_dir = data_home_dir + 'test'\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,batch_size=20, target_size=(dims,dims), class_mode='binary',color_mode='grayscale')\n",
    "\n",
    "#now evaluate the model using the generator\n",
    "[test_loss, test_acc] = model.evaluate(test_generator, steps=600/20)\n",
    "print(\"Test_acc: \"+str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2vy9httSiBt"
   },
   "source": [
    "Plot the results using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9LxnCkvSiBt"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.plot(epochs,acc,'bo', label='Training acc')\n",
    "plt.plot(epochs,val_acc,'b', label='Validation acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mN_J3UrLRQiW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of male_female_basic_example.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/kmjohnson3/ML4MI_BootCamp/blob/master/MaleFemaleRadiograph/male_female_basic_example.ipynb",
     "timestamp": 1629398242572
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
