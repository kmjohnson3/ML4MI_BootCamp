{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQfkzl7ZyVIO"
   },
   "source": [
    "This is an MRI based reconstruction demo, for 2D MRI data. The network is relatively similar to the recent AutoMap technique (https://arxiv.org/abs/1704.08841). This is a relatively 'brute force' aproach to image reconstruction in which the transoform is given no direct knowledge of the physics (although the network architecture is a bit tuned to the problem). In this work, we are assuming one direction is fully sampled (i.e. frequency encoded).\n",
    "\n",
    "# MRI Sampling\n",
    "In MRI the data is often discretely Fourier transoformed in one direction leading to the discretized signal model:\n",
    "\n",
    "$s(k)=\\sum_{j=1}^{N}\\rho (x_j)e^{i2\\pi kx}$\n",
    "\n",
    "The expected reconstruction for fully sampled data is an inverse discrete Fourier transform: \n",
    "\n",
    "$s(x)=\\sum_{j=1}^{N}s(k_j)e^{i2\\pi k_j x}$\n",
    "\n",
    "# Questions to think about:\n",
    "1) What is the minimal network architecture to compute a DFT? It's a square matrix multiply.\n",
    "\n",
    "2) What is the apropriate loss function if we wish to train an image reconstruction? \n",
    "\n",
    "3) What is the role of the convolutional layers? When are they needed?\n",
    "\n",
    "4) What is the network learning if you train on simulated images?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CRqgrJE2Ta5"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEeJpTYyyVIQ"
   },
   "outputs": [],
   "source": [
    "''' \n",
    "In python you need to import libraries in order to use them. \n",
    "'''\n",
    "\n",
    "# Import tensorflow ( we will use keras from tensorflow)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load Keras\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "  \n",
    "# Utilities\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Some support functions\n",
    "def montage( img_in, size=(3,5) ):\n",
    "    for j in range(size[0]):\n",
    "        plot_image = img_in[0+size[1]*j,:,:]\n",
    "        for i in range(size[1]-1):\n",
    "            plot_image = np.concatenate((plot_image, img_in[1+i+size[1]*j,:,:]), axis=1)\n",
    "        \n",
    "        if j == 0:\n",
    "            img = plot_image\n",
    "        else:\n",
    "            img = np.concatenate((img,plot_image),axis=0)\n",
    "    return img\n",
    "  \n",
    "def complex_to_channels( img_in):\n",
    "  return(np.stack(img_in.real,img_in.imag))\n",
    "  \n",
    "def channels_to_complex( img_in):\n",
    "  return(img_in[...,0]+1j*img_in[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIIWqihvqkcb",
    "outputId": "4d51fbac-d117-44c2-94e2-fa4735fcb46c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Mount your google drive, we'll grab data from the shared folder\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wkyR05heyVIV",
    "outputId": "6197da8e-9eb8-459d-a18a-a56fa04d9c9e"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Copy the data locally to make a bit faster\n",
    "'''\n",
    "!echo \"Copying Data Locally (Image Recon)\"\n",
    "!rsync --progress \"/content/drive/My Drive/ML4MI_BOOTCAMP_DATA/ImageSynthesis.tar\" /home/\n",
    "!tar xf \"/content/drive/My Drive/ML4MI_BOOTCAMP_DATA/ImageSynthesis.tar\" --directory /home/\n",
    "!rsync --progress \"/content/drive/My Drive/ML4MI_BOOTCAMP_DATA/Example_MRI_Data.h5\" /home/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vi9ablPpyVIT"
   },
   "source": [
    "# Training Images\n",
    "We are training this network using a simulation enviroment. Images are grabbed from a set of MRI brain images. This example is using the output dicoms which have been preprocessed. We then simulate the image to MRI raw data conversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZFxAwy-rUsm",
    "outputId": "a35a040d-6da7-4045-c691-b932f2e4ab14"
   },
   "outputs": [],
   "source": [
    "#Subsampling facter to reduce memory and computational burden\n",
    "subsample = 2\n",
    "\n",
    "# load training, validation, and testing data\n",
    "# adding a singleton dimension\n",
    "import h5py\n",
    "with h5py.File('/home/ImageSynthesis/data/ImageTranslationData.hdf5','r') as hf:\n",
    "    \n",
    "    # Stack the data from two contrasts\n",
    "    x_train = np.array(hf['trainX'])[:,::subsample,::subsample]\n",
    "    x_train = np.concatenate((x_train,np.array(hf['trainY'])[:,::subsample,::subsample]),axis=0)\n",
    "    \n",
    "    # Stack the data from two contrasts (validate)\n",
    "    x_val = np.array(hf['valX'])[:,::subsample,::subsample]\n",
    "    x_val = np.concatenate((x_val,np.array(hf['valX'])[:,::subsample,::subsample]),axis=0)\n",
    "\n",
    "# Input images are Dicoms which are magnitude, add 2nd channel of zeros\n",
    "x_train = np.stack((x_train,np.zeros(x_train.shape,dtype=x_train.dtype)), -1)\n",
    "x_val = np.stack((x_val,np.zeros(x_val.shape,dtype=x_train.dtype)), -1)\n",
    "\n",
    "print(f'Validate Dataset Size {x_val.shape}')\n",
    "print(f'Train Dataset Size {x_train.shape}')\n",
    "N = x_train.shape[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdaPO4_syVIa"
   },
   "source": [
    "# Simulate Sampling\n",
    "MRI data generation is aproximately dsicrete sampling of a continous Fourier transform the the data. In this example, we are using a Discrete Fourier transform to aproximate this. We also consider the case when we randomly remove data points. This would allow us to go faster and is used in compressed sensing application ( e.g. https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.21391 ). Noise is added a complex, white, gaussian noise (MRI noise is so called Johnson/Nyquist noise). Things to try:\n",
    "\n",
    "1) Add higher levels of noise. What happens to the training rate and output images? \n",
    "\n",
    "2) Increase the undersampling rate. How does the neural network compare to traditional aproaches? \n",
    "\n",
    "3) Comment the FFT shift, does the network still learn the transform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XdM9OkvyVIc",
    "outputId": "fce7cadd-2284-4f51-bd44-c1db2af4ac79"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The creates a sampling mask which can be used to subsample the data.\n",
    "'''\n",
    "\n",
    "# Get the number of phase encodes\n",
    "undersample_factor = 1.0 \n",
    "noise_level = 0.001; \n",
    "\n",
    "number_phase_encodes = int(N/undersample_factor)\n",
    "print('Using ' + str(number_phase_encodes) + ' phase encode')\n",
    "\n",
    "# Create a random mask to resample the data\n",
    "idx = np.full(N, False)\n",
    "idx[:number_phase_encodes] = True\n",
    "np.random.seed(1) # Keep this one so code is reproducible\n",
    "np.random.shuffle(idx)\n",
    "sampling_mask = idx\n",
    "\n",
    "\n",
    "'''\n",
    "Fourier transform, subsample, and add noise (Train Data)\n",
    "'''\n",
    "Nexamples = x_train.shape[0]\n",
    "kspace_train = np.zeros((Nexamples,N,number_phase_encodes,2),x_train.dtype)\n",
    "for example in range(x_train.shape[0]):\n",
    "  \n",
    "  if example % 1000 == 0:\n",
    "    print(f'Working on example {example} of {Nexamples}')\n",
    "      \n",
    "  # Grab one image\n",
    "  temp = x_train[example,:,:,0] + 1j*x_train[example,:,:,1]\n",
    "  \n",
    "  # Fourier Transform\n",
    "  kspace_temp = np.fft.fftn(temp,axes=(1,))/N\n",
    "  kspace_temp = np.fft.fftshift(kspace_temp,axes=(1,))\n",
    "  kspace_temp =np.stack( (kspace_temp.real, kspace_temp.imag), axis=-1)\n",
    "  \n",
    "  # Subsample\n",
    "  kspace_temp = kspace_temp[:,sampling_mask,:]\n",
    "  \n",
    "  # Add noise\n",
    "  kspace_temp += noise_level*np.random.randn(*kspace_temp.shape)\n",
    "\n",
    "  # Put back\n",
    "  kspace_train[example,:,:,:] = kspace_temp\n",
    "  \n",
    "print('Dimensions of training data are ' + str(kspace_train.shape) + '[ Examples x Nx x Ny x Channels]')\n",
    "\n",
    "\n",
    "'''\n",
    "Fourier transform, subsample, and add noise (Validate Data) \n",
    "'''\n",
    "Nexamples = x_val.shape[0]\n",
    "kspace_val = np.zeros((Nexamples,N,number_phase_encodes,2),x_train.dtype)\n",
    "for example in range(x_val.shape[0]):\n",
    "  \n",
    "  if example % 1000 == 0:\n",
    "    print(f'Working on example {example} of {Nexamples}')\n",
    "      \n",
    "  # Grab one image\n",
    "  temp = x_val[example,:,:,0] + 1j*x_val[example,:,:,1]\n",
    "  \n",
    "  # Fourier Transform\n",
    "  kspace_temp = np.fft.fftn(temp,axes=(1,))/N\n",
    "  kspace_temp = np.fft.fftshift(kspace_temp,axes=(1,))\n",
    "  kspace_temp =np.stack( (kspace_temp.real, kspace_temp.imag), axis=-1)\n",
    "  \n",
    "  # Subsample\n",
    "  kspace_temp = kspace_temp[:,sampling_mask,:]\n",
    "  \n",
    "  # Add noise\n",
    "  kspace_temp += noise_level*np.random.randn(*kspace_temp.shape)\n",
    "\n",
    "  # Put back\n",
    "  kspace_val[example,:,:,:] = kspace_temp\n",
    "  \n",
    "print('Dimensions of validation data are ' + str(kspace_val.shape) + '[ Examples x Nx x Ny x Channels]')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "rypEBBdfyVIl",
    "outputId": "ccd56a3e-9b7f-4f65-ff6c-cdbc02e4cddf"
   },
   "outputs": [],
   "source": [
    "example = 400\n",
    "\n",
    "# Show one image and k-space pair(should be whale)\n",
    "img = x_train[example,:,:,0] + 1j*x_train[example,:,:,1]\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.abs(img),cmap='gray')\n",
    "plt.title('Grayscale')\n",
    "\n",
    "img = kspace_train[example,:,:,0] + 1j*kspace_train[example,:,:,1]\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.abs(img),cmap='gray')\n",
    "plt.title('K-Space (1D FFT)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYe5C1eayVIq"
   },
   "source": [
    "# Build the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEykndHfyVIr",
    "outputId": "efa0992d-8904-4c79-e5f3-e65b1c02db37"
   },
   "outputs": [],
   "source": [
    "# Input is subsampled k-space, two channels for real/imag\n",
    "inputs = Input(shape=(N,number_phase_encodes,2), dtype='float32')\n",
    "\n",
    "# This is a bit of a trick but is two fully connected layers along the 2nd dimension. There is only a Fourier transform in 1 dimension.\n",
    "x = keras.layers.Conv2D(2*N,kernel_size=(1,number_phase_encodes),padding='valid',activation='linear', use_bias=False)(inputs)\n",
    "x = keras.layers.Permute((1,3,2))(x) \n",
    "x = keras.layers.Conv2D(2*N,kernel_size=(1,2*N),activation='linear',padding='valid',use_bias=False)(x)\n",
    "x = keras.layers.Reshape((N,N,2))(x)\n",
    "\n",
    "# This is a pretty simple multiple convolution\n",
    "x = keras.layers.Conv2D(16,kernel_size=(3,3),activation='relu',padding='same',use_bias=True)(x)\n",
    "x = keras.layers.Conv2D(16,kernel_size=(3,3),activation='relu',padding='same',use_bias=True)(x)\n",
    "x = keras.layers.Conv2D(2,kernel_size=(3,3),activation='relu',padding='same',name='out_image',use_bias=True)(x)\n",
    "\n",
    "# Recon Network\n",
    "model = Model(inputs=inputs,outputs=x)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='mean_squared_error')\n",
    "\n",
    "# Print a summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0FarDmdyVIu"
   },
   "source": [
    "# Build a callback\n",
    "This is a custom callback. The callback is a subclass of keras.callbacks.Callback and we replace the function calls we want to behave differently. The main objective of this callback is to allow realtime updates of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAqhZ0b3yVIv"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    This is a traing callback that the fitting algorithm will run during training\n",
    "'''\n",
    "class TraingCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure(figsize=(10,3))\n",
    "        self.logs = []\n",
    "        self.floor_epoch = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "    \n",
    "    #def on_train_end( self, logs={}):\n",
    "        # Do nothing\n",
    "        \n",
    "    #def on_batch_begin(self, batch, logs={}): \n",
    "        # Do nothing \n",
    "        \n",
    "    #def on_batch_end(self, batch, logs={}):\n",
    "        \n",
    "        #if batch%128==0:\n",
    "                     \n",
    "    def on_epoch_begin(self,epoch,logs={}):\n",
    "        self.floor_epoch = epoch\n",
    "        \n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        print(logs)\n",
    "        self.floor_epoch = epoch\n",
    "        self.loss = logs['loss']\n",
    "        self.val_loss = logs['val_loss']\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        self.fig = plt.figure(figsize=(10,3))\n",
    "\n",
    "\n",
    "        # self.params\n",
    "        #{'verbose': 1, 'nb_epoch': 12, 'batch_size': 128, 'metrics': ['loss', 'acc', 'val_loss', 'val_acc'], 'nb_sample': 60000, 'do_validation': True}\n",
    "        #batch_size = self.params['batch_size']\n",
    "\n",
    "        example = np.random.randint(10000)\n",
    "        example = 400 \n",
    "\n",
    "        '''\n",
    "            Run a test case\n",
    "        '''        \n",
    "        # Test with above image\n",
    "        kspace1image = kspace_val[example,:,:,:]\n",
    "        kspace1image = np.expand_dims(kspace1image,0)\n",
    "        act_image = x_val[example,:,:,:]\n",
    "        predicted_image = np.squeeze(model.predict(x=kspace1image))\n",
    "\n",
    "        act_image = act_image[:,:,0] + 1j*act_image[:,:,1]\n",
    "        predicted_image = predicted_image[:,:,0] + 1j*predicted_image[:,:,1]\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(np.abs(predicted_image), cmap='gray',vmin=0,vmax=1)\n",
    "        plt.title('Predicted Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(np.abs(act_image),cmap='gray',vmin=0,vmax=1)\n",
    "        plt.title('True Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        '''\n",
    "        Plot the Losses \n",
    "        '''\n",
    "        plt.subplot(131)\n",
    "        plt.semilogy(self.losses, label=\"Loss\")\n",
    "        plt.semilogy(self.val_losses, label=\"Loss (validation)\")\n",
    "        plt.legend()\n",
    "\n",
    "        print(f'Epoch = {self.floor_epoch} Loss = {self.loss}, Val Loss = {self.val_loss}')\n",
    "        plt.show();\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNWmO6ZLyVI0"
   },
   "source": [
    "# Run the model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "zpLk8hSVyVI1",
    "outputId": "5dd5aa86-784f-4203-9f08-894bf8b4460f"
   },
   "outputs": [],
   "source": [
    "# This will be limited by GPU memory for more complex networks\n",
    "batch_size  = 128\n",
    "\n",
    "# Create the callback object \n",
    "training_callback = TraingCallback()\n",
    "\n",
    "# Run model fit\n",
    "hist = model.fit(x=kspace_train, # Input to NN\n",
    "                 y=x_train, # Expected output\n",
    "                 batch_size=batch_size, # Minibatch size\n",
    "                 epochs=10, # Times to raster through data\n",
    "                 callbacks=[training_callback],  # Run this function during training\n",
    "                 shuffle=True,# Shuffle the cases\n",
    "                 verbose=True, # Print output\n",
    "                 validation_batch_size=1,\n",
    "                 validation_data=(kspace_val,x_val) # data for validation\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "FItk3W_byVI4",
    "outputId": "e801fd45-a99e-495e-b11f-46c19d707101"
   },
   "outputs": [],
   "source": [
    "example = 400\n",
    "\n",
    "# Test with synthetic data\n",
    "kspace = kspace_val[example,...]\n",
    "kspace = np.expand_dims(kspace,0)\n",
    "\n",
    "image = x_val[example,...]\n",
    "image = np.expand_dims(image,0)\n",
    "\n",
    "\n",
    "predicted_image = np.squeeze(model.predict(x=kspace))\n",
    "error = model.evaluate(kspace,image)\n",
    "\n",
    "# Convert to complex\n",
    "predicted_image = channels_to_complex(predicted_image)\n",
    "act_image = channels_to_complex(x_val[example,...])\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(11, 3), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(131)\n",
    "plt.imshow(np.abs(predicted_image),cmap='gray',vmin=0,vmax=1)\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.title('Predicted')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.abs(act_image),cmap='gray',vmin=0,vmax=1)\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.title('True Image')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.abs(act_image-predicted_image),cmap='gray',vmin=0)\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.title('Difference Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-txDIz5lyVI9"
   },
   "source": [
    "# Compare to least squares solution with data\n",
    "Here we compare to an alterantive aproach, regularied least squares. In this technique, we build an encoding matrix which simulates the data acquisition. Then we minimize:\n",
    "\n",
    "$\\parallel Ex-d \\parallel_2 +  \\lambda \\parallel x \\parallel_2$\n",
    "\n",
    "Where $\\lambda$ is a factor that regularizes the solution when its illposed ( see https://en.wikipedia.org/wiki/Tikhonov_regularization ). The solution to this set of equations is:\n",
    "\n",
    "$ \\widetilde{x} = (E^hE + \\lambda I)^{-1}E^hd$\n",
    "\n",
    "Where I is an identity matrix. Similar to the neural network this is an aproximate solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "sfsr-k_-yVI_",
    "outputId": "b4221a61-2669-4dd4-e722-7bfd01182276"
   },
   "outputs": [],
   "source": [
    "# Lets also solve this a different way using a matrix inverse\n",
    "def DFT_matrix(N):\n",
    "    i, j = np.meshgrid(np.arange(N), np.arange(N))\n",
    "    omega = np.exp( 2 * math.pi * 1J / N )\n",
    "    W = np.power( omega, i * j ) / N #math.sqrt(N)\n",
    "    return W\n",
    "\n",
    "E = DFT_matrix(N)\n",
    "E = np.fft.fftshift(E,axes=(0,))\n",
    "E = E[idx,:]\n",
    "\n",
    "# Grab the data\n",
    "D = np.matrix.getH(channels_to_complex(kspace_val[400,...]))\n",
    "\n",
    "# Solve for psuedo inverse\n",
    "Eh = np.matrix.getH(E)\n",
    "EhE = np.matmul(Eh,E)\n",
    "Ei = np.linalg.inv(EhE + 0.000001*np.identity(N))\n",
    "EiEh = np.matmul(Ei,Eh)\n",
    "\n",
    "linear_algebra_prediction = np.transpose(np.matmul(EiEh,D))\n",
    "    \n",
    "plt.figure(figsize=(11, 11), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(np.abs(linear_algebra_prediction),cmap='gray',vmin=0)\n",
    "plt.axis('off')\n",
    "plt.title('Least Squares Solution')\n",
    "plt.subplot(234)\n",
    "plt.imshow(np.abs(linear_algebra_prediction-act_image),cmap='gray',vmin=0,vmax=0.2)\n",
    "plt.axis('off')\n",
    "plt.title('Difference Least Squares')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.imshow(np.abs(predicted_image),cmap='gray',vmin=0,vmax=1)\n",
    "plt.axis('off')\n",
    "plt.title('Neural Net Prediction')\n",
    "plt.subplot(235)\n",
    "plt.imshow(np.abs(predicted_image-act_image),cmap='gray',vmin=0,vmax=0.2)\n",
    "plt.axis('off')\n",
    "plt.title('Difference Neural Net')\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.imshow(np.abs(act_image),cmap='gray',vmin=0,vmax=1)\n",
    "plt.axis('off')\n",
    "plt.title('Actual Image')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Image Domain Mean Squared Error NN = ' + str(np.sum(np.square(abs(np.squeeze(predicted_image) - act_image)))) )\n",
    "print('Image Domain Mean Squared Error LS = ' + str(np.sum(np.square(abs(linear_algebra_prediction - act_image)))) )\n",
    "\n",
    "# Lets also get the kspace error\n",
    "kspace_NN = np.matmul(E,np.squeeze(predicted_image))\n",
    "kspace_LA = np.matmul(E,linear_algebra_prediction)\n",
    "\n",
    "# Difference \n",
    "diff_kspace_NN = kspace_NN - D\n",
    "diff_kspace_LA = kspace_LA - D\n",
    "print('Kspace Mean Squared Error NN = ' + str(np.sum(np.square(abs(diff_kspace_NN)))) )\n",
    "print('Kspace Mean Squared Error LS = ' + str(np.sum(np.square(abs(diff_kspace_LA)))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bErWlC1oyVJD"
   },
   "source": [
    "# Load real MRI data to test\n",
    "This is actual acquired MRI data from a brain scan consisting. The data size is larger and we crop in k-space. Just to make things doable in a short time we are keeping everything 1D, as above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Wsb0va1yVJE",
    "outputId": "466c23c7-9162-457a-df7c-bb8a576fb6a1"
   },
   "outputs": [],
   "source": [
    "# Load a Kspace dataset from an actual acquisition\n",
    "with h5py.File('/home/Example_MRI_Data.h5','r') as hf:\n",
    "    kspace_mri = np.array(hf['Kspace'])\n",
    "\n",
    "#Crop Kspace\n",
    "crop = ( kspace_mri.shape[-2] - N ) // 2\n",
    "kspace_mri = kspace_mri[...,::subsample,crop:-crop]\n",
    "    \n",
    "print(f'Kspace size = {kspace_mri.shape} [ channels, slices, Nx, Ny], type = {kspace_mri.dtype}')\n",
    "coils = kspace_mri.shape[0]\n",
    "slices = kspace_mri.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDpA4fbOyVJI"
   },
   "source": [
    "# Run a traditional reconstruction \n",
    "The most common reconstruction on MRI scanners is to just do a discrete Fourier transform of the data. Just a note, the data actually has 48 recievers of the signal. We are taking the sum of sqyares to average these signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "Ek5-9k5dyVJJ",
    "outputId": "6cca6126-981b-4aa3-e1a1-6666b7823b82"
   },
   "outputs": [],
   "source": [
    "# Traditional recon of fully sampled data\n",
    "image_full = np.fft.ifftn(kspace_mri,axes=(-1,))\n",
    "\n",
    "# do sum of squares to average coils (detectors)\n",
    "image_full = np.sum(abs(image_full),axis=0)\n",
    "image_full = np.sqrt(image_full)\n",
    "\n",
    "# Make a montage (there are other options)\n",
    "plot_image = montage(image_full[8::2,:,:])  \n",
    "    \n",
    "# Show the image\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(plot_image,aspect=1,interpolation='bilinear',cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('DFT of Kspace')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zFZ9MqfyVJL"
   },
   "source": [
    "# Do inference on the real MRI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWezUcd-9zC1"
   },
   "source": [
    "Machine Learning Based Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "JNKqr0LOyVJM",
    "outputId": "4eaa9cd8-3a01-42f5-cc4b-13a11e92af24"
   },
   "outputs": [],
   "source": [
    "# Subsample kspace and convert to channels\n",
    "kspace_mri2 = kspace_mri[:,:,:,sampling_mask]\n",
    "kspace_mri2 = np.stack((kspace_mri2.real,kspace_mri2.imag),axis=-1)\n",
    "\n",
    "\n",
    "kspace_mri2 = np.reshape(kspace_mri2,(-1,N,number_phase_encodes,2))\n",
    "print(kspace_mri2.shape)\n",
    "\n",
    "# Run model\n",
    "image_NN = model.predict(x=kspace_mri2)\n",
    "print(image_NN.shape)\n",
    "\n",
    "\n",
    "# Reshape\n",
    "image_NN = np.reshape( image_NN,(coils,slices,N,N,2))\n",
    "image_NN = channels_to_complex(image_NN)\n",
    "\n",
    "# do sum of squares to average coils (detectors)\n",
    "image_NN = np.sum(abs(image_NN),axis=0)\n",
    "image_NN = np.sqrt(image_NN)\n",
    "\n",
    "# Make a montage (there are other options)\n",
    "plot_image = montage( image_NN[8::2,:,:])\n",
    "\n",
    "# Show the image\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(plot_image,aspect=1,interpolation='bilinear',cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Neural network prediction from Kspace')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Af-0f8ds9n_m"
   },
   "source": [
    "Linear algebra based solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "DB9r2kdbyVJQ",
    "outputId": "e8805bf2-924e-4885-dad6-e9357af9095a"
   },
   "outputs": [],
   "source": [
    "image_LA = np.zeros(image_full.shape,dtype=image_full.dtype)\n",
    "\n",
    "for k in range(slices):\n",
    "\n",
    "  # Subsample kspace and convert to channels\n",
    "  kspace_mri2 = np.squeeze(kspace_mri[:,k,:,:])\n",
    "  kspace_mri2 = kspace_mri2[:,:,sampling_mask]\n",
    "\n",
    "  kspace_mri2 = np.reshape(kspace_mri2,(-1,number_phase_encodes))\n",
    "  kspace_mri2 = np.expand_dims(kspace_mri2,-1)\n",
    "  \n",
    "  # Also do for Least squares estimate\n",
    "  image = np.matmul(EiEh,kspace_mri2)\n",
    "  image = np.reshape(image,newshape=(coils,N,N))\n",
    "\n",
    "  # do sum of squares to average coils (detectors)\n",
    "  image = np.sum(abs(image),axis=0)\n",
    "  image = np.sqrt(image)\n",
    "\n",
    "  image_LA[k,:,:] = np.fliplr(image)\n",
    "\n",
    "# Make a montage (there are other options)\n",
    "plot_image = montage( image_LA[8::2,:,:])\n",
    "\n",
    "# Show the image\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(plot_image,aspect=1,interpolation='bilinear',cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Linear algebra prediction from Kspace')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR50C3vkyVJT"
   },
   "source": [
    "# Now compare the solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "vTsV6JDcyVJT",
    "outputId": "51b52c5a-2c4c-463f-d623-de6aa741b8c0"
   },
   "outputs": [],
   "source": [
    "slice = 24\n",
    "\n",
    "print(image_LA.shape)\n",
    "print(image_NN.shape)\n",
    "print(image_full.shape)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(131)\n",
    "plt.imshow(abs(image_LA[slice,:,:]),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Linear Algebra')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(abs(image_NN[slice,:,:]),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Neural Net')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(abs(image_full[slice,:,:]),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "liC8He132W2-",
    "outputId": "dd7f458c-22ed-48b0-a344-400ce48d6dcd"
   },
   "outputs": [],
   "source": [
    "# Slice for viewing\n",
    "slice = 24\n",
    "\n",
    "# Scale to minimize difference (scaling unimportant in MRI)\n",
    "scale_LA = np.sum( image_full*np.conj(image_LA)) /np.sum(image_LA**2)\n",
    "scale_NN = np.sum( image_full*np.conj(image_NN)) /np.sum(image_NN**2)\n",
    "\n",
    "diff_LA = scale_LA*image_LA - image_full\n",
    "diff_NN = scale_NN*image_NN - image_full\n",
    "\n",
    "# Print Error\n",
    "error_LA = np.linalg.norm(diff_LA)/np.linalg.norm(image_full)\n",
    "error_NN = np.linalg.norm(diff_NN)/np.linalg.norm(image_full)\n",
    "\n",
    "print(f'Image MSE Linear Algebra = {error_LA}')\n",
    "print(f'Image MSE Neural Network = {error_NN}')\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(131)\n",
    "plt.imshow(abs(diff_LA[slice,:,:]),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Linear Algebra')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(abs(diff_NN[slice,:,:]),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Neural Net')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(abs(image_full[slice,:,:]),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P3_AoG-9__n"
   },
   "source": [
    "# Image Recon Challenge\n",
    "Can you fix the image reconstruction example?  The challenge is to reconstruct the images with the following paramaters:\n",
    "\n",
    "undersample_factor = 1.5 \n",
    "noise_level = 0.001; \n",
    "\n",
    "The challenge is to minimize the error (Image MSE Neural Network) in the above code block. Send your submissions (screenshot) to kmjohnson3@wisc.edu by the deadline to be entered. It is ok to work in groups. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CoLab_AutoMap_Recon.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
