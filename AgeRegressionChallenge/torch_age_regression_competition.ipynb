{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wW5nbFKxdboN",
    "outputId": "6713bf56-4a7f-4d4c-a90f-ac259f8ca195"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGolRNlFdc7l",
    "outputId": "8203ff69-5d97-40d1-ae72-49f347e5a9e9"
   },
   "outputs": [],
   "source": [
    "!echo \"Copying Data Locally (Age Regression)\"\n",
    "!tar xf \"/content/drive/My Drive/ML4MI_BOOTCAMP_DATA/AgeRegressionChallenge.tar\" --directory /home/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xpnw04u9csRF"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItiHjOi2csRH"
   },
   "source": [
    "Load training, validation, and testing data.\n",
    "Convert to nummpy array, add singleton dimension in channel position (1 channel -- grayscale). Edit path as needed. PyTorch expects images in the  [batch, channel, dim1, dim2] format (channels first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_E-ERQ73csRH"
   },
   "outputs": [],
   "source": [
    "datapath = '/home/AgeRegressionChallenge/Data/Pneumothorax.h5'\n",
    "\n",
    "with h5py.File(datapath,'r') as f:\n",
    "    X_test = np.array(f.get('input_test')).astype(np.float32)[:,np.newaxis,:,:]\n",
    "    Y_test = np.array(f.get('target_test')).astype(np.float32)[:,np.newaxis]\n",
    "    X_train = np.array(f.get('input_train')).astype(np.float32)[:,np.newaxis,:,:] \n",
    "    Y_train = np.array(f.get('target_train')).astype(np.float32)[:,np.newaxis] \n",
    "    X_val =  np.array(f.get('input_val')).astype(np.float32)[:,np.newaxis,:,:]  \n",
    "    Y_val = np.array(f.get('target_val')).astype(np.float32)[:,np.newaxis]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdTUst1GcsRJ"
   },
   "source": [
    "For PyTorch we will need a data loader. This is just a simple loader without augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EY51XBz_csRJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Create datasets\n",
    "dataset_train = Dataset( X_train, Y_train)\n",
    "dataset_val = Dataset( X_val, Y_val)\n",
    "\n",
    "# Create data loader to handle shuffling, batching, etc\n",
    "train_generator = torch.utils.data.DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "val_generator = torch.utils.data.DataLoader(dataset_val, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3MP9vTycsRL"
   },
   "source": [
    "## <font color='red'>PyTorch Model</font> \n",
    "This is a based on a series of convolutions followed by fully connected layers (similar to ResNet) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXB4Wk3JcsRM",
    "outputId": "312b4b7e-31f7-4200-885d-a1c01cc4102a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlock(torch.nn.Module):\n",
    "  '''Residual Block with a shortcut\n",
    "  '''\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "    super(ResBlock, self).__init__()\n",
    "\n",
    "    # First convolution\n",
    "    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3,3), padding='same')\n",
    "    self.norm1 = nn.BatchNorm2d(out_channels)\n",
    "    self.act1 = torch.nn.ReLU()\n",
    "\n",
    "    # Second convolution\n",
    "    self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3,3), padding='same')\n",
    "    self.norm2 = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    # Shortcut \n",
    "    self.convs =  nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1,1), padding='same')\n",
    "    self.act2 = torch.nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    shortcut = self.convs(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.norm1(x)\n",
    "    x = self.act1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.norm2(x)\n",
    "    x = x + shortcut\n",
    "    x = self.act2(x)\n",
    "    return x\n",
    "\n",
    "class AgeNet(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, depth=6, initial_features=32, input_size=256):\n",
    "    super(AgeNet, self).__init__()\n",
    "\n",
    "    in_channels = 1\n",
    "    out_channels = initial_features\n",
    "    im_size = 256\n",
    "\n",
    "    # This will build the list of operators, similar to keras sequential which each being a convolution followed by activation\n",
    "    layers = []\n",
    "    for l in range(depth):\n",
    "      layers.append(ResBlock(in_channels, out_channels))\n",
    "      in_channels = out_channels\n",
    "      layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "      im_size = im_size // 2\n",
    "          \n",
    "    # This stores the layers in a list that will be tracked for backpropogation\n",
    "    self.convolutions = nn.ModuleList(layers)\n",
    "\n",
    "    # Fully connected layers\n",
    "    self.fc1 = nn.Linear( im_size**2 * out_channels, 512)\n",
    "    self.act1 = nn.ReLU()\n",
    "    self.fc2 = nn.Linear( 512, 1)\n",
    "\n",
    "  def forward(self, image):\n",
    "    for l in self.convolutions:\n",
    "      image = l(image)\n",
    "    \n",
    "    # Flatten\n",
    "    image = image.view(image.size(0), -1)\n",
    "    \n",
    "    # Fully connected\n",
    "    image = self.fc1(image)\n",
    "    image = self.act1(image)\n",
    "    image = self.fc2(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# To run the model we need to create an object based on those class definitions above\n",
    "age_model = AgeNet()\n",
    "\n",
    "# Models have a device they run on. We need to put the model on the gpu\n",
    "age_model = age_model.cuda()\n",
    "\n",
    "# Torch summary enables similar formatting to Keras\n",
    "from torchsummary import summary\n",
    "summary(age_model, (1,256,256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMIYQ2eLcsRP"
   },
   "source": [
    "## <font color='red'>Run the model fitting</font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0Rr4pgCcsRS"
   },
   "source": [
    "Fit the model. Modify the epochs/batch_size as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Kalq8OzcsRS"
   },
   "outputs": [],
   "source": [
    "# Define an optimizer \n",
    "optimizer = torch.optim.Adam( age_model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define a loss function\n",
    "loss_fcn = nn.MSELoss()\n",
    "\n",
    "# Get a device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Ensure the model weights are on the desired device\n",
    "age_model.to(device)\n",
    "\n",
    "# Define number of epochs\n",
    "n_epochs = 50\n",
    "\n",
    "# Empty list to store losses over epochs\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Epoch loop\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "  # Put the model in train mode\n",
    "  age_model.train()\n",
    "\n",
    "  # Loop over training batches\n",
    "  train_loss_avg = 0.0\n",
    "  for x, y in train_generator:\n",
    "    \n",
    "    # Move data to the GPU\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    y_guess = age_model(x)\n",
    "\n",
    "    # Loss\n",
    "    loss = loss_fcn( y_guess, y)\n",
    "\n",
    "    # Store loss \n",
    "    train_loss_avg += loss.detach()\n",
    "\n",
    "    # Backwards with perform back propogation to get weights\n",
    "    loss.backward()\n",
    "    \n",
    "    # Take a gradient descent step\n",
    "    optimizer.step()\n",
    "\n",
    "  # Store the average loss\n",
    "  train_loss_avg /= len(train_generator)\n",
    "  train_losses.append(train_loss_avg)\n",
    "\n",
    "  # Switch to eval mode (weights fixed)\n",
    "  age_model.eval()\n",
    "\n",
    "  # Loop eval batches\n",
    "  val_loss_avg = 0.0\n",
    "  for count, (x, y) in enumerate(val_generator):\n",
    "\n",
    "    # Move data to the GPU\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "   \n",
    "    # Forward pass\n",
    "    y_guess = age_model(x)\n",
    "\n",
    "    # Loss\n",
    "    loss = loss_fcn( y_guess, y)\n",
    "    val_loss_avg += loss.detach()\n",
    "\n",
    "  # Store the average loss\n",
    "  val_loss_avg /= len(val_generator)\n",
    "  val_losses.append(val_loss_avg)\n",
    "\n",
    "  print(f'Epoch = {epoch} Loss = {train_loss_avg}, Val Loss = {val_loss_avg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA_Rf-IGcsRU"
   },
   "source": [
    "Plot the training/validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7H3E5EacsRV"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(train_losses,'bo', label='Training mse')\n",
    "plt.semilogy(val_losses,'b', label='Validation mse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_j593KNcsRY"
   },
   "source": [
    "This is the code to use to evaluate your network -- don't change it. Take a screen shot of the output to submit to the competition! (everyone should submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfFhZpTocsRY"
   },
   "outputs": [],
   "source": [
    "Y_pred = []\n",
    "for idx in range(X_test.shape[0]):\n",
    "  x = X_test[idx][np.newaxis,...]\n",
    "  x = torch.tensor(x)\n",
    "  \n",
    "  # Move data to the GPU\n",
    "  x = x.to(device)\n",
    "  \n",
    "  # Forward pass\n",
    "  Y_pred.append(age_model(x).detach().cpu().numpy())\n",
    "Y_pred = np.array(Y_pred)\n",
    "\n",
    "Y_pred = np.squeeze(Y_pred)  #remove the singleton dimension for analysis\n",
    "Y_test = np.squeeze(Y_test)  \n",
    "plt.scatter(Y_test, Y_pred, s=2)\n",
    "plt.xlabel('True age')\n",
    "plt.ylabel('Predicted age')\n",
    "plt.show()\n",
    "corr = np.corrcoef(Y_pred, Y_test)   #get correlation matrix\n",
    "print(\"Correlation coefficient: \" + str(corr[0,1]))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of age_regression_competition.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
